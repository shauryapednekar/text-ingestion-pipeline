{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -i https://test.pypi.org/simple/ easy-ingest-text==0.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from typing import List\n",
    "\n",
    "import easy_ingest_text.defaults\n",
    "from easy_ingest_text.embed_text import Embedder\n",
    "from easy_ingest_text.enhanced_document import EnhancedDocument\n",
    "from easy_ingest_text.ingest_text import Ingester\n",
    "from easy_ingest_text.load_text import Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s -  %(filename)s:%(lineno)d - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoader(Loader):\n",
    "    \"\"\"Custom logic for converting files to EnhancedDocuments.\"\"\"\n",
    "\n",
    "    def file_to_docs(self, file_path: str) -> List[EnhancedDocument]:\n",
    "        file_extension = file_path.split(\".\")[-1]\n",
    "        if file_extension == \"json\":\n",
    "            with open(file_path) as fin:\n",
    "                try:\n",
    "                    data = json.load(fin)\n",
    "                    text = data[\"text\"]\n",
    "                    # TODO(STP): Add the filename to the metadata.\n",
    "                    metadata = {}\n",
    "                    for key in {\n",
    "                        \"title\",\n",
    "                        \"url\",\n",
    "                        \"site_full\",\n",
    "                        \"language\",\n",
    "                        \"published\",\n",
    "                    }:\n",
    "                        if key in data:\n",
    "                            metadata[key] = data[key]\n",
    "                    if \"source\" in metadata:\n",
    "                        # HACK(STP): Since source is a reserved keyword for\n",
    "                        # document metadata, we need to rename it here.\n",
    "                        metadata[\"source_\"] = metadata[\"source\"]\n",
    "                    metadata[\"source\"] = file_path\n",
    "                    return [\n",
    "                        EnhancedDocument(page_content=text, metadata=metadata)\n",
    "                    ]\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to parse {fin}: {e}. Skipping for now\")\n",
    "                    return []\n",
    "        else:\n",
    "            return super().file_to_docs(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 14:50:48 -  SentenceTransformer.py:197 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted ../financial_dataset.zip into financial_dataset\n",
      "Extracted financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_04_112b52537b67659ad3609a234388c50a.zip into financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_04_112b52537b67659ad3609a234388c50a\n",
      "Deleted financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_04_112b52537b67659ad3609a234388c50a.zip\n",
      "Extracted financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_02_112b52537b67659ad3609a234388c50a.zip into financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_02_112b52537b67659ad3609a234388c50a\n",
      "Deleted financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_02_112b52537b67659ad3609a234388c50a.zip\n",
      "Extracted financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_05_112b52537b67659ad3609a234388c50a.zip into financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_05_112b52537b67659ad3609a234388c50a\n",
      "Deleted financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_05_112b52537b67659ad3609a234388c50a.zip\n",
      "Extracted financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_03_112b52537b67659ad3609a234388c50a.zip into financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_03_112b52537b67659ad3609a234388c50a\n",
      "Deleted financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_03_112b52537b67659ad3609a234388c50a.zip\n",
      "Extracted financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_01_112b52537b67659ad3609a234388c50a.zip into financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_01_112b52537b67659ad3609a234388c50a\n",
      "Deleted financial_dataset/3811_112b52537b67659ad3609a234388c50a/2018_01_112b52537b67659ad3609a234388c50a.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ingesting files:  81%|████████  | 406/500 [00:14<00:03, 28.89files/s]2024-08-10 14:52:26 -  embed_text.py:318 - INFO - \n",
      "Successfully saved vectorstore of length 3920 to: faiss_index\n",
      "Ingesting files:  81%|████████  | 406/500 [00:18<00:04, 21.86files/s]\n"
     ]
    }
   ],
   "source": [
    "vectorstore_config = easy_ingest_text.defaults.DEFAULT_VECTORSTORES_CONFIG\n",
    "vectorstore_config[\"FAISS\"][\"save_local_config\"][\"save_local\"] = True\n",
    "embedder = Embedder(vectorstore_config=vectorstore_config)\n",
    "ingester = Ingester(loader=CustomLoader(), embedder=embedder)\n",
    "# NOTE(STP): You need to upload the dataset to the current directory (`/content`) for this to work.\n",
    "# The demo dataset used can be found here: https://www.kaggle.com/datasets/jeet2016/us-financial-news-articles\n",
    "ingester.ingest_dataset(\n",
    "    input_dir=\"../financial_dataset.zip\",\n",
    "    is_zipped=True,\n",
    "    save_intermediate_docs=True,\n",
    "    output_dir=\"output_financial_dataset\",\n",
    "    detailed_progress=True,\n",
    "    max_files=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaurya/foo/src/ingestion-pipeline/demos/venv2/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/shaurya/foo/src/ingestion-pipeline/demos/venv2/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents stored in FAISS vectorstore: 3920\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from easy_ingest_text.defaults import DEFAULT_VECTORSTORES_CONFIG, DEFAULT_EMBEDDERS_CONFIG\n",
    "\n",
    "hf_embedder = HuggingFaceEmbeddings(**DEFAULT_EMBEDDERS_CONFIG[\"HuggingFace\"])\n",
    "load_local_config = DEFAULT_VECTORSTORES_CONFIG[\"FAISS\"][\"load_local_args\"]\n",
    "load_local_config[\"embeddings\"] = hf_embedder\n",
    "vectorstore_instance = FAISS.load_local(**load_local_config)\n",
    "num_documents = len(vectorstore_instance.index_to_docstore_id)\n",
    "print(f\"Total number of documents stored in FAISS vectorstore: {num_documents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x7f1d18623f10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Page Content: Where Food Comes From, Inc. is America’s trusted resource for third party verification of food production practices. The Company supports more than 15,000 farmers, ranchers, vineyards, wineries, processors, retailers, distributors, trade associations, consumer brands and restaurants with a wide variety of value-added services through its IMI Global, International Certification Services, Validus Verification Services, SureHarvest, A Bee Organic and Sterling Solutions units. In addition, the\n",
      " ... \n",
      "Metadata: {'language': 'english', 'title': 'Where Food Comes From (WFCF) Acquires Organic Verification Software Maker Sow Organic – the North American Leader in Certification Software for Organic Certifiers and Producers', 'published': '2018-05-17T21:28:00.000+03:00', 'url': 'http://www.cnbc.com/2018/05/17/globe-newswire-where-food-comes-from-wfcf-acquires-organic-verification-software-maker-sow-organic-a-the-north-american-leader-in.html', 'source': 'financial_dataset/2018_05_112b52537b67659ad3609a234388c50a/news_0037385.json', 'content_hash': '0bcd7a2c-aa53-59ee-a1d1-f3070f65c435', 'metadata_hash': 'cf0cdd42-f36a-5409-8e4f-36bb61c1fcf6', 'document_hash': '83523b81-da34-5a5b-baed-b8d442e999a5'}\n",
      "\n",
      "-----\n",
      "* Page Content: About Where Food Comes From, Inc.\n",
      " ... \n",
      "Metadata: {'language': 'english', 'title': 'Where Food Comes From (WFCF) Acquires Organic Verification Software Maker Sow Organic – the North American Leader in Certification Software for Organic Certifiers and Producers', 'published': '2018-05-17T21:28:00.000+03:00', 'url': 'http://www.cnbc.com/2018/05/17/globe-newswire-where-food-comes-from-wfcf-acquires-organic-verification-software-maker-sow-organic-a-the-north-american-leader-in.html', 'source': 'financial_dataset/2018_05_112b52537b67659ad3609a234388c50a/news_0037385.json', 'content_hash': 'e164a4fe-6d68-5fc2-b516-e69e46956e84', 'metadata_hash': 'cf0cdd42-f36a-5409-8e4f-36bb61c1fcf6', 'document_hash': '21e7207b-a9d3-540e-9374-81b68baa4b77'}\n",
      "\n",
      "-----\n",
      "* Page Content: Brazilian producers in the nation’s key center-west agricultural belt usually plant soy in the summer and corn right after the oilseed is harvested in a crop rotation system.\n",
      "“Soy brings corn together. If soy production expands, corn follows,” Fogaça said.\n",
      "Along with the new factories, Longping plans to build research centers to improve its corn seeds and to start developing new soy and sorghum seeds, the executives said.\n",
      " ... \n",
      "Metadata: {'language': 'english', 'title': \"China's Longping sees Brazil corn expansion, targets seeds market\", 'published': '2018-05-29T21:05:00.000+03:00', 'url': 'https://www.reuters.com/article/us-brazil-corn-lpht/chinas-longping-sees-brazil-corn-expansion-targets-seeds-market-idUSKCN1IU2ER', 'source': 'financial_dataset/2018_05_112b52537b67659ad3609a234388c50a/news_0055330.json', 'content_hash': 'f53152d5-2d4a-504d-9372-5d0ea39e8645', 'metadata_hash': '69afe38f-9cd2-5de3-9d70-cad79d36f2bb', 'document_hash': '624f3268-2d25-55e6-b02a-14d91209d8b0'}\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "results = vectorstore_instance.similarity_search(query=\"agriculture\",k=3)\n",
    "for doc in results:\n",
    "    print(f\"* Page Content: {doc.page_content}\\n ... \\nMetadata: {doc.metadata}\\n\\n-----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easy-ingest-demos-v2",
   "language": "python",
   "name": "easy-ingest-demos-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
